{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import math\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "import paddle.nn.functional as F\n",
    "from paddle import ParamAttr\n",
    "from paddle.nn.initializer import Normal, Constant\n",
    "from ppdet.modeling.proposal_generator import AnchorGenerator\n",
    "from ppdet.core.workspace import register\n",
    "from ppdet.modeling.layers import ConvNormLayer\n",
    "from .fcos_head import ScaleReg\n",
    "from ppdet.modeling.bbox_utils import distance2bbox, bbox2distance, batch_distance2bbox, bbox_center\n",
    "from paddle.fluid.dygraph import parallel_helper\n",
    "from ppdet.data.transform.atss_assigner import bbox_overlaps\n",
    "\n",
    "__all__ = ['SCRFDHead']\n",
    "\n",
    "\n",
    "def batch_kps2distance(points, kps, max_dis=None, eps=0.1):\n",
    "    \"\"\"Decode bounding box based on distances.\n",
    "    Args:\n",
    "        points: (Tensor): boxes center with shape (N, 2), \"x, y\" format.\n",
    "        kps (Tensor): Shape (n, K), \"xyxy\" format\n",
    "        max_dis (float): Upper bound of the distance.\n",
    "        eps (float): a small value to ensure target < max_dis, instead <=\n",
    "    Returns:\n",
    "        Tensor: Decoded distances.\n",
    "    \"\"\"\n",
    "\n",
    "    preds = []\n",
    "    points = paddle.tile(\n",
    "        points, repeat_times=[kps.shape[0] // points.shape[0], 1])\n",
    "    for i in range(0, kps.shape[1], 2):\n",
    "        px = kps[:, i] - points[:, i % 2]\n",
    "        py = kps[:, i + 1] - points[:, i % 2 + 1]\n",
    "        if max_dis is not None:\n",
    "            px = paddle.clip(px, min=0, max=max_dis - eps)\n",
    "            py = paddle.clip(py, min=0, max=max_dis - eps)\n",
    "        preds.append(px)\n",
    "        preds.append(py)\n",
    "    return paddle.stack(preds, -1)\n",
    "    # kps[..., 0::2] -= points[..., 0].unsqueeze(axis=-1)\n",
    "\n",
    "   # kps[..., 1::2] -= points[..., 1].unsqueeze(axis=-1)\n",
    "    # if max_dis is not None:\n",
    "    #     kps = paddle.clip(kps, min=0, max=max_dis - eps)\n",
    "    # return kps\n",
    "\n",
    "\n",
    "def batch_distance2kps(points, kps, max_shape=None):\n",
    "    preds = []\n",
    "    points = paddle.tile(points, repeat_times=[kps.shape[0], 1])\n",
    "    for i in range(0, kps.shape[2], 2):\n",
    "        px = points[..., 0] + kps[..., i]\n",
    "        py = points[..., 1] + kps[..., i + 1]\n",
    "        if max_shape is not None:\n",
    "            px = paddle.clip(px, min=0, max=max_shape[1])\n",
    "            py = paddle.clip(py, min=0, max=max_shape[0])\n",
    "        preds.append(px)\n",
    "        preds.append(py)\n",
    "    return paddle.stack(preds, -1)\n",
    "\n",
    "\n",
    "@register\n",
    "class SCRFDFeat(nn.Layer):\n",
    "    \"\"\"\n",
    "    PicoFeat of PicoDet\n",
    "    Args:\n",
    "        feat_in (int): The channel number of input Tensor.\n",
    "        feat_out (int): The channel number of output Tensor.\n",
    "        num_convs (int): The convolution number of the LiteGFLFeat.\n",
    "        norm_type (str): Normalization type, 'bn'/'sync_bn'/'gn'.\n",
    "        share_cls_reg (bool): Whether to share the cls and reg output.\n",
    "        act (str): The act of per layers.\n",
    "        use_se (bool): Whether to use se module.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 feat_in=24,\n",
    "                 feat_out=64,\n",
    "                 num_fpn_stride=3,\n",
    "                 num_convs=2,\n",
    "                 norm_type='gn',\n",
    "                 norm_decay=0,\n",
    "                 share_cls_reg=True,\n",
    "                 fpn_stride_share=True,\n",
    "                 act='relu',\n",
    "                 norm_group=16,\n",
    "                 use_dw_conv=False):\n",
    "        super(SCRFDFeat, self).__init__()\n",
    "        self.num_convs = num_convs\n",
    "        self.norm_type = norm_type\n",
    "        self.norm_group = norm_group\n",
    "        self.share_cls_reg = share_cls_reg\n",
    "        self.fpn_stride_share = fpn_stride_share\n",
    "        self.act = act\n",
    "        self.feat_out = feat_out\n",
    "        self.feat_in = feat_in\n",
    "        self.cls_convs = []\n",
    "        self.reg_convs = []\n",
    "        if use_dw_conv:\n",
    "            self.groups = feat_out\n",
    "        else:\n",
    "            self.groups = 1\n",
    "        if fpn_stride_share:\n",
    "            num_fpn_stride = 1\n",
    "\n",
    "        for stage_idx in range(num_fpn_stride):\n",
    "            cls_subnet_convs = []\n",
    "            reg_subnet_convs = []\n",
    "            for i in range(self.num_convs):\n",
    "                in_c = feat_in if i == 0 else feat_out\n",
    "                if use_dw_conv:\n",
    "                    cls_conv_dw = self.add_sublayer(\n",
    "                        'cls_conv_dw{}.{}'.format(stage_idx, i),\n",
    "                        ConvNormLayer(\n",
    "                            ch_in=in_c,\n",
    "                            ch_out=feat_out,\n",
    "                            filter_size=3,\n",
    "                            stride=1,\n",
    "                            groups=feat_out,\n",
    "                            norm_type=norm_type,\n",
    "                            norm_groups=self.norm_groups,\n",
    "                            bias_on=False,\n",
    "                            lr_scale=1.))\n",
    "                    cls_subnet_convs.append(cls_conv_dw)\n",
    "                    cls_conv_pw = self.add_sublayer(\n",
    "                        'cls_conv_pw{}.{}'.format(stage_idx, i),\n",
    "                        ConvNormLayer(\n",
    "                            ch_in=in_c,\n",
    "                            ch_out=feat_out,\n",
    "                            filter_size=1,\n",
    "                            stride=1,\n",
    "                            norm_type=norm_type,\n",
    "                            norm_groups=self.norm_groups,\n",
    "                            bias_on=False,\n",
    "                            lr_scale=2.))\n",
    "                    cls_subnet_convs.append(cls_conv_pw)\n",
    "                else:\n",
    "                    cls_conv = self.add_sublayer(\n",
    "                        'cls_conv_{}.{}'.format(stage_idx, i),\n",
    "                        ConvNormLayer(\n",
    "                            ch_in=in_c,\n",
    "                            ch_out=feat_out,\n",
    "                            filter_size=3,\n",
    "                            stride=1,\n",
    "                            groups=self.groups,\n",
    "                            norm_type=norm_type,\n",
    "                            norm_decay=norm_decay,\n",
    "                            norm_groups=self.norm_group,\n",
    "                            bias_on=False))\n",
    "                    cls_subnet_convs.append(cls_conv)\n",
    "\n",
    "                if not self.share_cls_reg:\n",
    "                    if use_dw_conv:\n",
    "                        reg_conv_dw = self.add_sublayer(\n",
    "                            'reg_conv_dw{}.{}'.format(stage_idx, i),\n",
    "                            ConvNormLayer(\n",
    "                                ch_in=in_c,\n",
    "                                ch_out=feat_out,\n",
    "                                filter_size=5,\n",
    "                                stride=1,\n",
    "                                groups=feat_out,\n",
    "                                norm_type=norm_type,\n",
    "                                bias_on=False,\n",
    "                                lr_scale=1.))\n",
    "                        reg_subnet_convs.append(reg_conv_dw)\n",
    "                        reg_conv_pw = self.add_sublayer(\n",
    "                            'reg_conv_pw{}.{}'.format(stage_idx, i),\n",
    "                            ConvNormLayer(\n",
    "                                ch_in=in_c,\n",
    "                                ch_out=feat_out,\n",
    "                                filter_size=1,\n",
    "                                stride=1,\n",
    "                                norm_type=norm_type,\n",
    "                                bias_on=False,\n",
    "                                lr_scale=1.))\n",
    "                        reg_subnet_convs.append(reg_conv_pw)\n",
    "                    else:\n",
    "                        reg_conv = self.add_sublayer(\n",
    "                            'reg_conv_{}.{}'.format(stage_idx, i),\n",
    "                            ConvNormLayer(\n",
    "                                ch_in=in_c,\n",
    "                                ch_out=feat_out,\n",
    "                                filter_size=3,\n",
    "                                stride=1,\n",
    "                                groups=self.groups,\n",
    "                                norm_type=norm_type,\n",
    "                                norm_groups=self.norm_group,\n",
    "                                bias_on=False))\n",
    "                        reg_subnet_convs.append(reg_conv)\n",
    "            self.cls_convs.append(cls_subnet_convs)\n",
    "            self.reg_convs.append(reg_subnet_convs)\n",
    "\n",
    "    def act_func(self, x):\n",
    "        if self.act == \"leaky_relu\":\n",
    "            x = F.leaky_relu(x)\n",
    "        elif self.act == \"hard_swish\":\n",
    "            x = F.hardswish(x)\n",
    "        elif self.act == \"relu\":\n",
    "            x = F.relu(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, fpn_feat, stage_idx):\n",
    "        if not self.fpn_stride_share:\n",
    "            assert stage_idx < len(self.cls_convs)\n",
    "        else:\n",
    "            stage_idx = 0\n",
    "\n",
    "        cls_feat = fpn_feat\n",
    "        reg_feat = fpn_feat\n",
    "        kps_feat = fpn_feat\n",
    "        for i in range(len(self.cls_convs[stage_idx])):\n",
    "            cls_feat = self.act_func(self.cls_convs[stage_idx][i](cls_feat))\n",
    "            reg_feat = cls_feat\n",
    "            kps_feat = cls_feat\n",
    "            if not self.share_cls_reg:\n",
    "                reg_feat = self.act_func(self.reg_convs[stage_idx][i](reg_feat))\n",
    "        return cls_feat, reg_feat, kps_feat\n",
    "\n",
    "\n",
    "@register\n",
    "class SCRFDHead(nn.Layer):\n",
    "    \"\"\"Used in RetinaNet proposed in paper https://arxiv.org/pdf/1708.02002.pdf\n",
    "    \"\"\"\n",
    "    __inject__ = [\n",
    "        'conv_feat', 'anchor_generator', 'bbox_assigner', 'loss_class',\n",
    "        'loss_bbox', 'nms', 'loss_kps'\n",
    "    ]\n",
    "\n",
    "    def __init__(self,\n",
    "                 num_classes=1,\n",
    "                 conv_feat=None,\n",
    "                 anchor_generator=None,\n",
    "                 bbox_assigner=None,\n",
    "                 loss_class=None,\n",
    "                 loss_bbox=None,\n",
    "                 nms_pre=1000,\n",
    "                 nms=None,\n",
    "                 use_kps=False,\n",
    "                 num_kps=5,\n",
    "                 loss_kps=None,\n",
    "                 use_reg_scale=True):\n",
    "        super(SCRFDHead, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        # allow RetinaNet to use IoU based losses.\n",
    "        self.conv_feat = conv_feat\n",
    "        self.anchor_generator = anchor_generator\n",
    "        self.bbox_assigner = bbox_assigner\n",
    "        self.loss_class = loss_class\n",
    "        self.loss_bbox = loss_bbox\n",
    "        self.nms_pre = nms_pre\n",
    "        self.nms = nms\n",
    "        self.cls_out_channels = num_classes\n",
    "        self.use_reg_scale = use_reg_scale\n",
    "        self.use_kps = use_kps\n",
    "        self.NK = num_kps\n",
    "        self.loss_kps = loss_kps\n",
    "        self.init_layers()\n",
    "\n",
    "    def init_layers(self):\n",
    "        bias_init_value = -4.595\n",
    "        num_anchors = self.anchor_generator.num_anchors\n",
    "        self.num_anchors = num_anchors\n",
    "        self.scrfd_cls = nn.Conv2D(\n",
    "            in_channels=self.conv_feat.feat_out,\n",
    "            out_channels=self.cls_out_channels * num_anchors,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "            weight_attr=ParamAttr(initializer=Normal(\n",
    "                mean=0.0, std=0.01)),\n",
    "            bias_attr=ParamAttr(initializer=Constant(value=bias_init_value)))\n",
    "        self.scrfd_reg = nn.Conv2D(\n",
    "            in_channels=self.conv_feat.feat_out,\n",
    "            out_channels=4 * num_anchors,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "            weight_attr=ParamAttr(initializer=Normal(\n",
    "                mean=0.0, std=0.01)),\n",
    "            bias_attr=ParamAttr(initializer=Constant(value=0)))\n",
    "\n",
    "        self.reg_scale = nn.LayerList()\n",
    "        for i in range(len(self.anchor_generator.strides)):\n",
    "            if self.use_reg_scale:\n",
    "                self.reg_scale.append(ScaleReg())\n",
    "            else:\n",
    "                self.reg_scale.append(None)\n",
    "        if self.use_kps:\n",
    "            self.scrfd_kps = nn.Conv2D(\n",
    "                in_channels=self.conv_feat.feat_out,\n",
    "                out_channels=self.NK * 2 * num_anchors,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1,\n",
    "                weight_attr=ParamAttr(initializer=Normal(\n",
    "                    mean=0.0, std=0.01)),\n",
    "                bias_attr=ParamAttr(initializer=Constant(value=0)))\n",
    "\n",
    "    def forward(self, neck_feats):\n",
    "        # we use the same anchor for all images\n",
    "        anchors, num_anchors_list, stride_tensor_list = self.anchor_generator(\n",
    "            neck_feats, return_extra_info=True)\n",
    "        cls_logits_list = []\n",
    "        bboxes_pred_list = []\n",
    "        kps_pred_list = []\n",
    "        for i, neck_feat in enumerate(neck_feats):\n",
    "            conv_cls_feat, conv_reg_feat, conv_kps_feat = self.conv_feat(\n",
    "                neck_feat, i)\n",
    "            cls_logits = self.scrfd_cls(conv_cls_feat)\n",
    "            bbox_reg = self.scrfd_reg(conv_reg_feat)\n",
    "            if self.use_kps:\n",
    "                kps_pred = self.scrfd_kps(conv_kps_feat)\n",
    "            else:\n",
    "                kps_pred = paddle.zeros([\n",
    "                    bbox_reg.shape[0], self.NK * 2 * self.num_anchors,\n",
    "                    bbox_reg.shape[2], bbox_reg.shape[3]\n",
    "                ])\n",
    "            if self.reg_scale[i] is not None:\n",
    "                bbox_reg = self.reg_scale[i](bbox_reg)\n",
    "\n",
    "            cls_logits_list.append(\n",
    "                cls_logits.transpose([0, 2, 3, 1]).reshape(\n",
    "                    [0, -1, self.cls_out_channels]))\n",
    "            anchor_center = bbox_center(anchors[\n",
    "                i]) / self.anchor_generator.strides[i]\n",
    "            anchor_center = paddle.broadcast_to(anchor_center, [\n",
    "                bbox_reg.shape[0], anchor_center.shape[0],\n",
    "                anchor_center.shape[1]\n",
    "            ])\n",
    "            bbox_reg = bbox_reg.transpose([0, 2, 3, 1]).reshape([0, -1, 4])\n",
    "            bbox_pred = batch_distance2bbox(anchor_center, bbox_reg)\n",
    "            if not self.training:\n",
    "                bbox_pred *= self.anchor_generator.strides[i]\n",
    "            bboxes_pred_list.append(bbox_pred)\n",
    "            if self.use_kps:\n",
    "                kps_pred = kps_pred.transpose([0, 2, 3, 1]).reshape(\n",
    "                    [0, -1, self.NK * 2])\n",
    "                if not self.training:\n",
    "                    kps_pred = batch_distance2kps(anchor_center, kps_pred)\n",
    "                    kps_pred *= self.anchor_generator.strides[i]\n",
    "                kps_pred_list.append(kps_pred)\n",
    "\n",
    "        cls_logits = paddle.concat(cls_logits_list, axis=1)\n",
    "        bboxes_pred = paddle.concat(bboxes_pred_list, axis=1)\n",
    "        if self.use_kps:\n",
    "            kpses_pred = paddle.concat(kps_pred_list, axis=1)\n",
    "        else:\n",
    "            kpses_pred = None\n",
    "        anchors = paddle.concat(anchors, axis=0)\n",
    "        stride_tensor_list = paddle.concat(stride_tensor_list, axis=0)\n",
    "        stride_tensor_list = paddle.unsqueeze(stride_tensor_list, axis=0)\n",
    "        return (cls_logits, bboxes_pred, anchors, num_anchors_list,\n",
    "                stride_tensor_list, kpses_pred)\n",
    "\n",
    "    def get_loss(self, head_outputs, gt_meta):\n",
    "        \"\"\"Here we calculate loss for a batch of images.\n",
    "        We assign anchors to gts in each image and gather all the assigned\n",
    "        postive and negative samples. Then loss is calculated on the gathered\n",
    "        samples.\n",
    "        \"\"\"\n",
    "        cls_logits, bboxes_pred, anchors, num_anchors_list, stride_tensor_list, kpses_pred = head_outputs\n",
    "        gt_labels = gt_meta['gt_class']\n",
    "        gt_bboxes = gt_meta['gt_bbox']\n",
    "        pad_gt_mask = gt_meta['pad_gt_mask']\n",
    "        gt_kps_all = gt_meta['gt_keypoint']\n",
    "        bs, num, num_kps, len_kps = gt_kps_all.shape\n",
    "        gt_kps = gt_kps_all[..., :2].reshape([bs, num, -1])\n",
    "        gt_kps_mask = gt_kps_all[..., 2].reshape(\n",
    "            [bs, num, -1])[:, :, 0].unsqueeze(-1)\n",
    "        gt_kps = gt_kps * (gt_kps_mask * pad_gt_mask)\n",
    "\n",
    "        assigned_labels, assigned_bboxes, assigned_scores, assigned_kps = self.bbox_assigner(\n",
    "            anchors,\n",
    "            num_anchors_list,\n",
    "            gt_labels,\n",
    "            gt_bboxes,\n",
    "            pad_gt_mask,\n",
    "            bg_index=self.num_classes,\n",
    "            pred_bboxes=bboxes_pred.detach() * stride_tensor_list,\n",
    "            gt_kps=gt_kps)\n",
    "        #  # rescale bbox\n",
    "        assigned_bboxes /= stride_tensor_list\n",
    "        assigned_kps /= stride_tensor_list\n",
    "        flatten_cls_preds = cls_logits.reshape([-1, self.num_classes])\n",
    "        flatten_bboxes = bboxes_pred.reshape([-1, 4])\n",
    "        flatten_bbox_targets = assigned_bboxes.reshape([-1, 4])\n",
    "        flatten_labels = assigned_labels.reshape([-1])\n",
    "        flatten_assigned_scores = assigned_scores.reshape(\n",
    "            [-1, self.num_classes])\n",
    "        pos_inds = paddle.nonzero(\n",
    "            paddle.logical_and((flatten_labels >= 0),\n",
    "                               (flatten_labels < self.num_classes)),\n",
    "            as_tuple=False).squeeze(1)\n",
    "        num_total_pos = len(pos_inds)\n",
    "\n",
    "        if num_total_pos > 0:\n",
    "            pos_bbox_targets = paddle.gather(\n",
    "                flatten_bbox_targets, pos_inds, axis=0)\n",
    "            pos_decode_bbox_pred = paddle.gather(\n",
    "                flatten_bboxes, pos_inds, axis=0)\n",
    "\n",
    "            pos_cls_pred = paddle.gather(\n",
    "                flatten_assigned_scores, pos_inds, axis=0)\n",
    "            weight_targets = pos_cls_pred.detach()\n",
    "            weight_targets = F.sigmoid(1 - weight_targets)\n",
    "            # weight_targets = F.sigmoid(weight_targets)\n",
    "Collaborator\n",
    "@yghstill yghstill on 15 Jun\n",
    "same as above\n",
    "\n",
    "@a-F1\tReply...\n",
    "            #  weight_targets = paddle.gather(\n",
    "            #      weight_targets.max(axis=1, keepdim=True), pos_inds, axis=0)\n",
    "\n",
    "            # regression loss\n",
    "            loss_iou = paddle.sum(\n",
    "                self.loss_bbox(pos_decode_bbox_pred, pos_bbox_targets,\n",
    "                               weight_targets))\n",
    "            # cal avg_factor\n",
    "            avg_factor = weight_targets.sum()\n",
    "            if paddle.fluid.core.is_compiled_with_dist(\n",
    "            ) and parallel_helper._is_parallel_ctx_initialized():\n",
    "                paddle.distributed.all_reduce(avg_factor)\n",
    "                avg_factor = paddle.clip(\n",
    "                    avg_factor / paddle.distributed.get_world_size(), min=1)\n",
    "            loss_iou /= avg_factor\n",
    "\n",
    "            if self.use_kps:\n",
    "                flatten_kpses_pred = kpses_pred.reshape([-1, self.NK * 2])\n",
    "                flatten_assigned_kps = assigned_kps.reshape([-1, self.NK * 2])\n",
    "                pos_kps_pred_mask = paddle.gather(\n",
    "                    flatten_assigned_kps, pos_inds,\n",
    "                    axis=0).sum(axis=-1).unsqueeze(axis=-1)\n",
    "                kpses_weight = paddle.where(pos_kps_pred_mask > 0,\n",
    "                                            weight_targets,\n",
    "                                            paddle.zeros_like(weight_targets))\n",
    "                anchors_center = (bbox_center(anchors) /\n",
    "                                  stride_tensor_list).squeeze(axis=0)\n",
    "                pos_kps_targets = batch_kps2distance(anchors_center,\n",
    "                                                     flatten_assigned_kps)\n",
    "                pos_kps_targets = paddle.gather(\n",
    "                    pos_kps_targets, pos_inds, axis=0)\n",
    "                pos_kps_pred = paddle.gather(\n",
    "                    flatten_kpses_pred, pos_inds, axis=0)\n",
    "\n",
    "                loss_kps = self.loss_kps(pos_kps_pred,\n",
    "                                         pos_kps_targets) * kpses_weight\n",
    "                loss_kps = paddle.sum(loss_kps)\n",
    "                if self.use_kps:\n",
    "                    loss_kps /= avg_factor\n",
    "            else:\n",
    "                loss_kps = paddle.zeros([1])\n",
    "        else:\n",
    "            loss_iou = paddle.zeros([1])\n",
    "            loss_kps = paddle.zeros([1])\n",
    "\n",
    "        # classification loss\n",
    "        num_total_pos = paddle.to_tensor(num_total_pos)\n",
    "        if paddle.fluid.core.is_compiled_with_dist(\n",
    "        ) and parallel_helper._is_parallel_ctx_initialized():\n",
    "            paddle.distributed.all_reduce(num_total_pos)\n",
    "            num_total_pos = paddle.clip(\n",
    "                num_total_pos / paddle.distributed.get_world_size(), min=1)\n",
    "        loss_cls = self.loss_class(\n",
    "            flatten_cls_preds,\n",
    "            (flatten_labels, paddle.flatten(assigned_scores).detach()),\n",
    "            avg_factor=num_total_pos.detach())\n",
    "\n",
    "        return {\n",
    "            'loss_class': loss_cls,\n",
    "            'loss_reg': loss_iou,\n",
    "            'loss_kps': loss_kps\n",
    "        }\n",
    "\n",
    "    def post_process(self, head_outs, img_shape, scale_factor):\n",
    "        pred_scores, pred_bboxes, anchors, num_anchors_list, \\\n",
    "            stride_tensor_list, kps_pred = head_outs\n",
    "        pred_scores = F.sigmoid(pred_scores.transpose([0, 2, 1]))\n",
    "\n",
    "        for i in range(len(pred_bboxes)):\n",
    "            pred_bboxes[i, :, 0] = pred_bboxes[i, :, 0].clip(\n",
    "                min=0, max=img_shape[i, 1])\n",
    "            pred_bboxes[i, :, 1] = pred_bboxes[i, :, 1].clip(\n",
    "                min=0, max=img_shape[i, 0])\n",
    "            pred_bboxes[i, :, 2] = pred_bboxes[i, :, 2].clip(\n",
    "                min=0, max=img_shape[i, 1])\n",
    "            pred_bboxes[i, :, 3] = pred_bboxes[i, :, 3].clip(\n",
    "                min=0, max=img_shape[i, 0])\n",
    "        # scale bbox to origin\n",
    "        scale_factor = scale_factor.flip([1]).tile([1, 2]).unsqueeze(1)\n",
    "        pred_bboxes /= scale_factor\n",
    "        bbox_pred, bbox_num, _ = self.nms(pred_bboxes, pred_scores)\n",
    "        return bbox_pred, bbox_num"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}